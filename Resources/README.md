# Resources

## Courses

### [Machine Learning by Andrew Ng - Coursera](https://www.coursera.org/learn/machine-learning)

This is one of the primer or starter courses if you are new to Machine Learning. The course requires the student to have basic knowledge of Linear Algebra. And it builds over it as it moves ahead. The course is a very basic ML course and covers all the concepts from Regression to SVMs to basics of Neural Networks.

### [Neural Networks for Machine Learning - Coursera](https://www.coursera.org/learn/neural-networks)

This course by Geoffrey Hinton (one of the pioneers of Deep Learning) dives more into the neural networks, basics of neural networks and various types of networks being used. It assumes a basic knowledge of ML and the Mathematical component is kept as intuitive as possible. The only backdrop of this course, can be the use of octave/matlab for assignments.

### [Neural Networks Class by Hugo Larochelle - UniversiteÂ´ de Sherbrooke](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)

Hugo Larochelle is a really good teacher and these series takes you through Neural Networks in the most detailed way and gives intuition into each concept with good amount of Mathematics involved.

### [Reinforcement Learning by Georgia Tech - Udacity](https://www.udacity.com/course/reinforcement-learning--ud600)

You should take this course if you have an interest in machine learning and the desire to engage with it from a theoretical perspective. Through a combination of classic papers and more recent work, you will explore automated decision-making from a computer-science perspective. You will examine efficient algorithms, where they exist, for single-agent and multi-agent planning as well as approaches to learning near-optimal decisions from experience. At the end of the course, you will replicate a result from a published paper in reinforcement learning.

### [Reinforcement Learning by David Silver](https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT)

These are series of lectures on basics of Reinforcement Learning by David Silver, Professor at University College of London and part of AlphaGo Team, Google Deepmind. You need a background of ML to get started with.

### [Deep Learning by Google - Udacity](https://www.udacity.com/course/deep-learning--ud730)

This course created by Google is an advanced level course and requires the person to know basics of ML. It has both practical and theoretical component. Practical component is based on Python and Tensorflow.

### [Deep NLP by Oxford University](https://github.com/oxford-cs-deepnlp-2017/lectures)

This is an applied course focussing on recent advances in analysing and generating speech and text using recurrent neural networks. We introduce the mathematical definitions of the relevant machine learning models and derive their associated optimisation algorithms. The course covers a range of applications of neural networks in NLP including analysing latent dimensions in text, transcribing speech to text, translating between languages, and answering questions. These topics are organised into three high level themes forming a progression from understanding the use of neural networks for sequential language modelling, to understanding their use as conditional language models for transduction tasks, and finally to approaches employing these techniques in combination with other mechanisms for advanced applications. Throughout the course the practical implementation of such models on CPU and GPU hardware is also discussed.


### [CS231n Convolutional Neural Networks for Visual Recognition - Stanford University](CS231n Convolutional Neural Networks for Visual Recognition)

One of the premier courses for Deep Learning in Images. Taken by Andrej Karpath, Fei Fei Li and Justin Johnson.


## Books

### [Artificial Intelligence - A Modern Approach by Peter Norvig and Stuart Russell](http://aima.cs.berkeley.edu/)

The leading text book on AI which covers the philosophical perspective, history and the introduction to emerging ideas of AI which have led to today's boom.

### [Deep Learning - Ian Goodfellow and Yoshua Bengio and Aaron Courville](http://deeplearningbook.org/)

The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. The online version of the book is now complete and will remain available online for free.

### [Reinforcement Learning - An Introduction By Richard S. Sutton and Andrew G. Barto](https://mitpress.mit.edu/books/reinforcement-learning)

In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.


## Research Papers

### [On the Origin of Deep Learning](https://arxiv.org/pdf/1702.07800.pdf)

This paper is a review of the evolutionary history of deep learning models. It covers from the genesis of neural networks when associationism modeling of the brain is studied, to the models that dominate the last decade of research in deep learning like convolutional neural networks, deep belief networks, and recurrent neural networks, and extends to popular recent models like variational autoencoder and generative adversarial nets. In addition to a review of these models, this paper primarily focuses on the precedents of the models above, examining how the initial ideas are assembled to construct the early models and how these preliminary models are developed into their current forms. Many of these evolutionary paths last more than half a century and have a diversity of directions. For example, CNN is built on prior knowledge of biological vision system; DBN is evolved from a trade-off of modeling power and computation complexity of graphical models and many nowadays models are neural counterparts of ancient linear models. This paper reviews these evolutionary paths and offers a concise thought flow of how these models are developed, and aims to provide a thorough background for deep learning. More importantly, along with the path, this paper summarizes the gist behind these milestones and proposes many directions to guide the future research of deep learning.
